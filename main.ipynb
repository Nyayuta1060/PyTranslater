%reset -f
# ライブラリのインストール
!pip install -U "transformers>=4.38.0" accelerate bitsandbytes sentencepiece "gradio>=4.0.0"

# ライブラリのインポート
import torch
import transformers
import gradio as gr
import traceback
from threading import Thread

# 1. モデルID
model_id = "elyza/ELYZA-japanese-Llama-2-7b-instruct"

# トークナイザーの準備
tokenizer = transformers.AutoTokenizer.from_pretrained(model_id)

# 4bit量子化の設定
quantization_config = transformers.BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.bfloat16,
)

# モデルの準備
model = transformers.AutoModelForCausalLM.from_pretrained(
    model_id,
    quantization_config=quantization_config,
    device_map="auto",
)

# torch.compileでモデルを高速化
if torch.__version__ >= "2.0.0":
    model = torch.compile(model)
print("✅ ELYZAモデルの読み込みとコンパイル完了。")


# プロンプト用の定数
B_INST, E_INST = "[INST]", "[/INST]"
B_SYS, E_SYS = "<<SYS>>\n", "\n<</SYS>>\n\n"

# 言語のマッピング
lang_map = {
    "日本語": "Japanese",
    "英語": "English",
    "中国語": "Chinese",
    "韓国語": "Korean",
    "ベトナム語": "Vietnamese",
    "ヒンディー語": "Hindi",
    "フランス語": "French",
    "ドイツ語": "German",
    "スペイン語": "Spanish",
    "イタリア語": "Italian",
    "ポルトガル語": "Portuguese",
    "ロシア語": "Russian",
}
# リアルタイム表示のためのStreamerクラス
class TextIteratorStreamer(transformers.TextStreamer):
    def __init__(self, tokenizer, skip_prompt=True, **kwargs):
        super().__init__(tokenizer, skip_prompt, **kwargs)
        self.text_queue = []
        self.stop_signal = None
    def on_finalized_text(self, text: str, stream_end: bool = False):
        self.text_queue.append(text)
        if stream_end:
            self.stop_signal = "END"
    def __iter__(self):
        return self
    def __next__(self):
        while len(self.text_queue) == 0:
            if self.stop_signal == "END":
                raise StopIteration()
        return self.text_queue.pop(0)

# 翻訳処理関数
def translate_text(text, source_lang, target_lang, temperature, top_p, repetition_penalty):
    yield {
        output_text: "",
        translate_btn: gr.Button("翻訳中...", interactive=False),
        status_display: gr.Markdown("翻訳中...")
    }

    try:
        if not text:
            yield {status_display: gr.Markdown("テキストを入力してください。")}
            return
        if source_lang == target_lang:
            yield {output_text: text, status_display: gr.Markdown("✅ 翻訳完了")}
            return

        instruction = f"Translate the following text from {lang_map[source_lang]} to {lang_map[target_lang]}."
        prompt = f"<s>{B_INST} {B_SYS}{instruction}{E_SYS}{text} {E_INST}"

        inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
        streamer = TextIteratorStreamer(tokenizer, skip_prompt=True)

        generation_kwargs = dict(
            inputs,
            streamer=streamer, max_new_tokens=512, do_sample=True,
            temperature=float(temperature), top_p=float(top_p),
            repetition_penalty=float(repetition_penalty),
        )

        thread = Thread(target=model.generate, kwargs=generation_kwargs)
        thread.start()

        buffer = ""
        for new_text in streamer:
            buffer += new_text
            yield {output_text: buffer}

        yield {
            translate_btn: gr.Button("翻訳する", interactive=True),
            status_display: gr.Markdown("✅ 翻訳完了")
        }

    except Exception as e:
        error_message = f"❌ エラーが発生しました: {str(e)}"
        print(traceback.format_exc())
        yield {
            translate_btn: gr.Button("翻訳する", interactive=True),
            status_display: gr.Markdown(error_message)
        }

# Gradio UIの構築
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("## 🌐 Colab-Trancelater v8")
    gr.Markdown("made by nyayuta")

    with gr.Row():
        with gr.Column(scale=5):
            source_lang = gr.Dropdown(choices=list(lang_map.keys()), value="日本語", label="翻訳元言語")
        with gr.Column(scale=1, min_width=100):
            swap_btn = gr.Button("🔄 入れ替え")
        with gr.Column(scale=5):
            target_lang = gr.Dropdown(choices=list(lang_map.keys()), value="英語", label="翻訳先言語")

    with gr.Row():
        input_text = gr.Textbox(lines=6, placeholder="翻訳したいテキストを入力してください", label="入力")
        output_text = gr.Textbox(lines=6, label="翻訳結果", interactive=False)

    with gr.Row(elem_id="buttons"):
        translate_btn = gr.Button("翻訳する", variant="primary")
        clear_btn = gr.Button("クリア")

    status_display = gr.Markdown("")

    # 各スライダーにinfo引数を追加して説明文を表示
    with gr.Accordion("⚙️ 高度な設定", open=False):
        gr.Markdown("翻訳の質を微調整するためのパラメータです。通常はデフォルトのままで問題ありません。")
        temperature = gr.Slider(
            minimum=0.1, maximum=1.0, value=0.7, step=0.1, label="Temperature",
            info="出力のランダム性。値を高くすると創造的に、低くすると無難な翻訳になります。"
        )
        top_p = gr.Slider(
            minimum=0.1, maximum=1.0, value=0.95, step=0.05, label="Top-p",
            info="単語選択の厳密さ。値を小さくすると、より一般的で安全な単語が選ばれやすくなります。"
        )
        repetition_penalty = gr.Slider(
            minimum=1.0, maximum=1.5, value=1.1, step=0.05, label="Repetition Penalty",
            info="同じ単語の繰り返しを防ぐペナルティ。1.0より大きいと効果があります。"
        )

    # ボタンのクリックイベント
    inputs = [input_text, source_lang, target_lang, temperature, top_p, repetition_penalty]
    outputs = [output_text, translate_btn, status_display]
    translate_btn.click(fn=translate_text, inputs=inputs, outputs=outputs)

    def swap_languages(source, target):
        return target, source
    swap_btn.click(fn=swap_languages, inputs=[source_lang, target_lang], outputs=[source_lang, target_lang])

    def clear_text():
        return "", "", ""
    clear_btn.click(fn=clear_text, outputs=[input_text, output_text, status_display])

print("\nGradioアプリを起動します...")
demo.launch(share=True, debug=True)